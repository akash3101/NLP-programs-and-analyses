{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modeling using Latent Semantic Analysis\n",
    "\n",
    "### Demonstrating NLP applications - Akash G\n",
    "\n",
    "137 articles have been mined from - **Times of India, Indian Express, The Economist, The Guardian** - with the central topic of discussion regarding **China**. Our attempt here is to find out the topics that can categorize these documents/articles, with the help of soft-clustering methods like **Latent Semantic Analysis**. This method essentially utilizes the **SVD** process and clusters the documents based on their vectorized positions in a dimensionally reduced space.\n",
    "\n",
    "&nbsp;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import math\n",
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/Akashgupta/Desktop/Rnlp/rpd/INDEXP.csv\")\n",
    "df2 = pd.read_csv(\"/Users/Akashgupta/Desktop/Rnlp/rpd/ECONOMIST.csv\")\n",
    "df3 = pd.read_csv(\"/Users/Akashgupta/Desktop/Rnlp/rpd/TIMESOFIND.csv\")\n",
    "df4 = pd.read_csv(\"/Users/Akashgupta/Desktop/Rnlp/rpd/GUARD.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df,df2,df3,df4]\n",
    "data = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**Below is the concatanated Dataframe consisting of articles from all the news sources put together.**\n",
    "\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ie_xi</td>\n",
       "      <td>Over the last six months, in the shadow of COV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ie_xi</td>\n",
       "      <td>In a widely noted and strongly criticised spee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>ie_xi</td>\n",
       "      <td>The Iranian government’s recent approval of a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ie_xi</td>\n",
       "      <td>Reports that Iran and China are close to concl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ie_xi</td>\n",
       "      <td>The recent re-emergence of terms like “Malabar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>gu_xi</td>\n",
       "      <td>The sight of young people anywhere being bruta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>gu_xi</td>\n",
       "      <td>Hong Kong is not yet cowed. That was, unquesti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>gu_xi</td>\n",
       "      <td>Strong national defence is the consequence of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>gu_xi</td>\n",
       "      <td>When Mike Pompeo spoke at the online Copenhage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>gu_xi</td>\n",
       "      <td>The Chinese assault on Indian troops near the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     title                                               text\n",
       "0    ie_xi  Over the last six months, in the shadow of COV...\n",
       "1    ie_xi  In a widely noted and strongly criticised spee...\n",
       "2    ie_xi  The Iranian government’s recent approval of a ...\n",
       "3    ie_xi  Reports that Iran and China are close to concl...\n",
       "4    ie_xi  The recent re-emergence of terms like “Malabar...\n",
       "..     ...                                                ...\n",
       "132  gu_xi  The sight of young people anywhere being bruta...\n",
       "133  gu_xi  Hong Kong is not yet cowed. That was, unquesti...\n",
       "134  gu_xi  Strong national defence is the consequence of ...\n",
       "135  gu_xi  When Mike Pompeo spoke at the online Copenhage...\n",
       "136  gu_xi  The Chinese assault on Indian troops near the ...\n",
       "\n",
       "[137 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datanew = df.append([df2,df3,df4], ignore_index = True)\n",
    "datanew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**Below is a regular expression code block to filter out non-textual characters from the article body**\n",
    "\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datanew['clean_text'] = datanew['text'].str.replace(\"[^a-zA-Z#]\",\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**The following code block is for tokenizing the document into words.**\n",
    "\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      [Over, the, last, six, months, in, the, shadow...\n",
      "1      [In, a, widely, noted, and, strongly, criticis...\n",
      "2      [The, Iranian, government, s, recent, approval...\n",
      "3      [Reports, that, Iran, and, China, are, close, ...\n",
      "4      [The, recent, re, emergence, of, terms, like, ...\n",
      "                             ...                        \n",
      "132    [The, sight, of, young, people, anywhere, bein...\n",
      "133    [Hong, Kong, is, not, yet, cowed, That, was, u...\n",
      "134    [Strong, national, defence, is, the, consequen...\n",
      "135    [When, Mike, Pompeo, spoke, at, the, online, C...\n",
      "136    [The, Chinese, assault, on, Indian, troops, ne...\n",
      "Name: clean_text, Length: 137, dtype: object\n"
     ]
    }
   ],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "tokenized_doc = datanew['clean_text'].apply(lambda x: x.split())\n",
    "tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if x not in stop_words])\n",
    "print(tokenized_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_tokenized_doc = []\n",
    "for i in range(len(tokenized_doc)):\n",
    "    t = ' '.join(tokenized_doc[i])\n",
    "    de_tokenized_doc.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**Here a term-document matrix is created by essentially vectorizing the documents by using TFIDF weighting.**\n",
    "\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137, 151212)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words = stop_words, use_idf = True, ngram_range = (1,3))\n",
    "X = vectorizer.fit_transform(de_tokenized_doc)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "**SVD is applied and 10 principal components are selected which essentially represent our 10 topics. The top 10 keywords are then listed according to each topic**\n",
    "\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic1: \n",
      "========\n",
      "china\n",
      "india\n",
      "chinese\n",
      "us\n",
      "indian\n",
      "xi\n",
      "world\n",
      "beijing\n",
      "military\n",
      "sea\n",
      "south\n",
      "mr\n",
      "would\n",
      "iran\n",
      "war\n",
      "countries\n",
      "china sea\n",
      "strategic\n",
      "opinion\n",
      "delhi\n",
      " \n",
      "topic2: \n",
      "========\n",
      "iran\n",
      "india\n",
      "afghanistan\n",
      "iran china\n",
      "chabahar\n",
      "tehran\n",
      "iranian\n",
      "indian\n",
      "strategic\n",
      "deep strategic\n",
      "deep strategic partnership\n",
      "strategic partnership\n",
      "partnership\n",
      "link\n",
      "port\n",
      "delhi\n",
      "investments\n",
      "rail\n",
      "deep\n",
      "chinese investments\n",
      " \n",
      "topic3: \n",
      "========\n",
      "iran\n",
      "human rights\n",
      "afghanistan\n",
      "rights\n",
      "sanctions\n",
      "iran china\n",
      "human\n",
      "tehran\n",
      "chabahar\n",
      "different\n",
      "nuclear\n",
      "iranian\n",
      "deep strategic\n",
      "deep strategic partnership\n",
      "cold\n",
      "trump\n",
      "argument based\n",
      "arms race\n",
      "classroom\n",
      "uighurs\n",
      " \n",
      "topic4: \n",
      "========\n",
      "india\n",
      "indian\n",
      "pla\n",
      "lac\n",
      "ladakh\n",
      "different\n",
      "india china\n",
      "war\n",
      "opinion\n",
      "border\n",
      "modi\n",
      "boundary\n",
      "cold\n",
      "military\n",
      "argument based\n",
      "arms race\n",
      "classroom\n",
      "galwan\n",
      "movements\n",
      "kashmir\n",
      " \n",
      "topic5: \n",
      "========\n",
      "sea\n",
      "china sea\n",
      "adiz\n",
      "south china sea\n",
      "south china\n",
      "south\n",
      "china\n",
      "us\n",
      "scs\n",
      "asean\n",
      "claims\n",
      "islands\n",
      "maritime\n",
      "waters\n",
      "fishing\n",
      "australia\n",
      "pacific\n",
      "east\n",
      "statement\n",
      "indo pacific\n",
      " \n",
      "topic6: \n",
      "========\n",
      "hong\n",
      "hong kong\n",
      "kong\n",
      "british\n",
      "law\n",
      "britain\n",
      "beijing\n",
      "us\n",
      "uk\n",
      "lam\n",
      "mrs\n",
      "new law\n",
      "democracy\n",
      "mainland\n",
      "mrs lam\n",
      "protest\n",
      "national security\n",
      "australia\n",
      "protesters\n",
      "legislation\n",
      " \n",
      "topic7: \n",
      "========\n",
      "pla\n",
      "combat\n",
      "command\n",
      "adiz\n",
      "military\n",
      "hong\n",
      "hong kong\n",
      "kong\n",
      "forces\n",
      "divisions\n",
      "army\n",
      "corps\n",
      "offensive\n",
      "troops\n",
      "lac\n",
      "mr\n",
      "infantry\n",
      "air\n",
      "warfare\n",
      "mr xi\n",
      " \n",
      "topic8: \n",
      "========\n",
      "xi\n",
      "mr xi\n",
      "deng\n",
      "mr\n",
      "mao\n",
      "party\n",
      "pla\n",
      "ccp\n",
      "opinion\n",
      "jinping\n",
      "xi jinping\n",
      "leader\n",
      "delhi\n",
      "asian\n",
      "century\n",
      "president xi\n",
      "indian express\n",
      "express\n",
      "power\n",
      "revolution\n",
      " \n",
      "topic9: \n",
      "========\n",
      "us\n",
      "command\n",
      "combat\n",
      "operations\n",
      "offensive\n",
      "corps\n",
      "world\n",
      "divisions\n",
      "britain\n",
      "strategic\n",
      "pacific\n",
      "pla\n",
      "war\n",
      "military\n",
      "australia\n",
      "defence\n",
      "elements\n",
      "strike\n",
      "indo pacific\n",
      "forces\n",
      " \n",
      "topic10: \n",
      "========\n",
      "xinjiang\n",
      "uighur\n",
      "rfa\n",
      "uighurs\n",
      "muslim\n",
      "british\n",
      "britain\n",
      "detention\n",
      "manchu\n",
      "centres\n",
      "chinese\n",
      "uk\n",
      "camps\n",
      "pakistan\n",
      "relatives\n",
      "manchus\n",
      "un\n",
      "region\n",
      "ms\n",
      "uighur workers\n",
      " \n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.extmath import randomized_svd\n",
    "\n",
    "U, sigma, VT = randomized_svd(X, n_components = 10, n_iter = 100, random_state = 122)\n",
    "\n",
    "for i, com in enumerate(VT):\n",
    "    terms_com = zip(terms, com)\n",
    "    sorted_terms = sorted(terms_com, key = lambda x:x[1],reverse = True)[:20]\n",
    "    print(\"topic\"+str(i+1)+\": \")\n",
    "    print(\"========\")\n",
    "    for t in sorted_terms:\n",
    "        print(t[0])\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp;\n",
    "\n",
    "We can see all the articles written about **China** can be grouped into 10 topics or categories as follows :- \n",
    "\n",
    "- **Topic 1** : These are articles that primarily focus on Indo-China geopolitical situations. These set of articles also have references to the US.\n",
    "\n",
    "- **Topic 2** : Articles grouped into this topic revolve around discussions involving **Iran, Afghanistan, Tehran, Chabahar**. They largely focus on how India's policy towards China is also influenced by other factors, particularly Iran and Afghanistan.\n",
    "\n",
    "- **Topic 3** : These articles also tend to focus on geopolitical situations that connect - **India, China, Iran, Afghanistan** but also tend to have a focus on **human rights** aspects as well. These probably refer to China's treatment of the Uiyghur Muslims.\n",
    "\n",
    "- **Topic 4** : Articles in this category are almost exclusively centered around the **India-China border problems** in **Ladakh**. \n",
    "\n",
    "- **Topic 5** : These articles focus on the **South China Sea** situation and how China is increasingly exerting its influence in this region. Prominent international groupings like **ASEAN** also find mention in these articles.\n",
    "\n",
    "- **Topic 6** : These articles focus on the **Hong Kong NSL** recently enacted by the Chinese government. These articles shed light on geopolitical relations between **Britain and China**.\n",
    "\n",
    "- **Topic 7** : These articles primarily report military action by China's **PLA** in the **ADIZ South China Sea** region.\n",
    "\n",
    "- **Topic 8** : Articles in this category have focussed on describing **Xi Jinping** and his connections with the ideologies of his predecessors like **Deng and Mao**.\n",
    "\n",
    "- **Topic 9** : These articles revolve around China's relations with **US and Britain**. It seems like these articles are associated with words like **combat, offensive and divisions** which give an idea about the negative sentiment associated in these geopolitical relations.\n",
    "\n",
    "- **Topic 10** : These articles highlight China's inhuman treatment of **Uighurs** in the **Xinjiang** province of China and the detention centres located there. \n",
    "\n",
    "&nbsp;\n",
    "\n",
    "**The aim of this analysis is to get an idea of what the world is writing about in the context of China. With a topic analysis we get to know the broad perceptions prevailing in countries when they discuss China**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
